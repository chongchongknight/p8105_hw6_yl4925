p8108\_hw6\_yl4925
================
Yiming Li
12/3/2021

``` r
library(tidyverse)
library(modelr)
library(mgcv)
```

## Problem1

``` r
birthweight_df = read.csv("./data/birthweight.csv") %>% 
  janitor::clean_names() 
```

``` r
sum(is.na(rowSums(birthweight_df)))
```

    ## [1] 0

There is no missing value.

Then we try to propose a linear regression model for the data. First, we
factor some variables

``` r
fct_birthweight_df = birthweight_df %>% 
  mutate(babysex = case_when(
    babysex == 1 ~ "male",
    babysex == 2 ~ "female"
  ), frace = case_when(
    frace == 1 ~ "white",
    frace == 2 ~ "black",
    frace == 3 ~ "asian",
    frace == 4 ~ "puerto_rican",
    frace == 8 ~ "other",
    frace == 9 ~ "unknown",
  ), malform = case_when(
    malform == 0 ~ "absent",
    malform == 1 ~ "present"
  ), mrace = case_when(
    mrace == 1 ~ "white",
    mrace == 2 ~ "black",
    mrace == 3 ~ "asian",
    mrace == 4 ~ "puerto_rican",
    mrace == 8 ~ "other"
  )) %>% 
  mutate(babysex = fct_infreq(babysex), 
         frace = fct_infreq(frace),
         mrace = fct_infreq(mrace),
         malform = fct_infreq(malform))
```

Then we use lm to regress all variables. And we try to exclude some
variables from our model.

``` r
original_fit = lm(bwt ~ ., data = fct_birthweight_df)
```

``` r
original_fit_df = original_fit %>% broom::tidy() 
original_fit_df %>% 
  filter(is.na(rowSums(select(original_fit_df, -term)))) %>% 
  select(term) %>% 
  knitr::kable()
```

| term    |
|:--------|
| pnumlbw |
| pnumsga |
| wtgain  |

We find there are three NA coefficients (pnumlbw, pnumsga and wtgain),
which means that these three variables could be linear combination of
other variables, so we do not choose these three variables as
predictors.

``` r
original_fit_df %>% 
  filter(p.value > 0.05) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable()
```

| term               |    estimate |   p.value |
|:-------------------|------------:|----------:|
| fincome            |   0.2898207 | 0.1065513 |
| fraceblack         |  14.3312853 | 0.7561682 |
| fracepuerto\_rican | -46.9962310 | 0.2929123 |
| fraceasian         |  21.2361118 | 0.7592729 |
| fraceother         |   4.2969242 | 0.9537446 |
| malformpresent     |   9.7649680 | 0.8900388 |
| menarche           |  -3.5507723 | 0.2200827 |
| mheight            |   9.7874130 | 0.3425881 |
| momage             |   0.7593479 | 0.5344182 |
| mracepuerto\_rican | -56.4787268 | 0.2109013 |
| mraceasian         | -91.3866079 | 0.2039079 |
| ppbmi              |   4.3537865 | 0.7700173 |
| ppwt               |  -3.4715550 | 0.1839131 |

The p values for these 13 variables are greater than 0.05, which means
that we could not reject null hypothesis (coefficient is zero). But for
mrace variable, some values of this variable are necessary (p value &lt;
0.05). So we remain mrace variables and only exclude frace (only the p
value for “unknown” &lt; 0.05), fincome, malform (only the p value for
“absent” &lt; 0.05), menarche, mheight, momage, ppbmi and ppwt.

Then we get a better model.

``` r
better_fit = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + 
                  parity + ppbmi + ppwt + smoken , data = fct_birthweight_df)
summary(better_fit)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ babysex + bhead + blength + delwt + gaweeks + 
    ##     mrace + parity + ppbmi + ppwt + smoken, data = fct_birthweight_df)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1101.89  -183.53    -2.52   174.72  2339.27 
    ## 
    ## Coefficients:
    ##                     Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       -5669.6216   101.0955 -56.082  < 2e-16 ***
    ## babysexfemale        28.3709     8.4578   3.354 0.000802 ***
    ## bhead               131.0913     3.4452  38.050  < 2e-16 ***
    ## blength              74.8239     2.0178  37.082  < 2e-16 ***
    ## delwt                 4.0857     0.3920  10.422  < 2e-16 ***
    ## gaweeks              11.6674     1.4618   7.981 1.84e-15 ***
    ## mraceblack         -145.5239     9.2254 -15.774  < 2e-16 ***
    ## mracepuerto_rican  -107.2366    19.0691  -5.624 1.99e-08 ***
    ## mraceasian          -79.5499    42.2934  -1.881 0.060052 .  
    ## parity               94.3584    40.3421   2.339 0.019383 *  
    ## ppbmi                -9.5824     2.5704  -3.728 0.000196 ***
    ## ppwt                 -0.9795     0.5659  -1.731 0.083553 .  
    ## smoken               -4.8751     0.5856  -8.325  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 272.4 on 4329 degrees of freedom
    ## Multiple R-squared:  0.7178, Adjusted R-squared:  0.717 
    ## F-statistic: 917.7 on 12 and 4329 DF,  p-value: < 2.2e-16

``` r
better_fit %>% 
  broom::tidy()
```

    ## # A tibble: 13 × 5
    ##    term               estimate std.error statistic   p.value
    ##    <chr>                 <dbl>     <dbl>     <dbl>     <dbl>
    ##  1 (Intercept)       -5670.      101.       -56.1  0        
    ##  2 babysexfemale        28.4       8.46       3.35 8.02e-  4
    ##  3 bhead               131.        3.45      38.0  1.49e-273
    ##  4 blength              74.8       2.02      37.1  1.23e-261
    ##  5 delwt                 4.09      0.392     10.4  3.90e- 25
    ##  6 gaweeks              11.7       1.46       7.98 1.84e- 15
    ##  7 mraceblack         -146.        9.23     -15.8  1.51e- 54
    ##  8 mracepuerto_rican  -107.       19.1       -5.62 1.99e-  8
    ##  9 mraceasian          -79.5      42.3       -1.88 6.01e-  2
    ## 10 parity               94.4      40.3        2.34 1.94e-  2
    ## 11 ppbmi                -9.58      2.57      -3.73 1.96e-  4
    ## 12 ppwt                 -0.979     0.566     -1.73 8.36e-  2
    ## 13 smoken               -4.88      0.586     -8.33 1.12e- 16

``` r
fct_birthweight_df %>% 
  modelr::add_residuals(better_fit) %>% 
  modelr::add_predictions(better_fit) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5) + 
  geom_smooth(color = "blue", method = "lm", se = FALSE) + 
  labs(
    title = "lm_model residual VS prediction"
  )
```

<img src="p8105_hw6_yl4925_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />
We find the slope of smooth line for residual VS predictor is almost 0,
which means that these points are symmetric about the predictor-axis.
The reason for this might be that when we use linear regression, we set
a normal distribution residual (*ϵ* \~ N (0, *σ*<sup>2</sup>)).

Then we compare our model to the main effect model and interaction
model.

``` r
cv_df = crossv_mc(fct_birthweight_df, 100) 
```

``` r
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

``` r
cv_df = 
  cv_df %>% 
  mutate(
    my_mod = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + 
                  parity + ppbmi + ppwt + smoken , data = .x)),
    len_ges_mod = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    headcir_len_sex_mod = map(train, ~lm(bwt ~ blength + bhead + babysex + 
                                           blength * bhead + blength * babysex + bhead * babysex + 
                                           blength*bhead*babysex, data = .x))) %>% 
  mutate(
    rmse_my = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_main_effect = map2_dbl(len_ges_mod, test, ~rmse(model = .x, data = .y)),
    rmse_interaction = map2_dbl(headcir_len_sex_mod, test, ~rmse(model = .x, data = .y)))
```

``` r
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_reorder(model, rmse)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "RMSE for three models"
  )
```

<img src="p8105_hw6_yl4925_files/figure-gfm/unnamed-chunk-14-1.png" width="90%" />

We find the root mean square error for my model is the smallest, and
interaction model has a middle root mean square error, and the main
effect model has largest root mean square error. \#\# problem 2

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Use broom tidy to get estimate for intercept and slope.

``` r
log_result_df = weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  mutate(term = case_when(
    term == "(Intercept)" ~ "beta0",
    term == "tmin" ~ "beta1"
  )) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  mutate(log = log(beta0 * beta1))
```

Show the distribution.

``` r
log_result_df %>% 
  ggplot(aes(x = log)) +
  geom_density() +
  labs(
    x = "log(beta0 * beta1)",
    title = "Distribution of Estimates of log(beta0 * beta1)")
```

<img src="p8105_hw6_yl4925_files/figure-gfm/unnamed-chunk-17-1.png" width="90%" />
Distribution is close to normal distribution.

Show mean, 95% CI, and sd for
*l**o**g*(*β*<sub>1</sub> \* *β*<sub>2</sub>)

``` r
log_numerical_result = log_result_df %>% 
  summarize(
    lower_limit = quantile(log, 0.025),
    upper_limit = quantile(log, 0.975),
    log_mean = mean(log),
    log_sd = sd(log)) 
log_numerical_result %>% 
  knitr::kable()
```

| lower\_limit | upper\_limit | log\_mean |   log\_sd |
|-------------:|-------------:|----------:|----------:|
|     1.964954 |     2.058045 |  2.012994 | 0.0238808 |

``` r
log_mean = log_numerical_result$log_mean
log_sd = log_numerical_result$log_sd
log_lower = log_numerical_result$lower_limit
log_upper = log_numerical_result$upper_limit
```

The mean for *l**o**g*(*β*<sub>1</sub> \* *β*<sub>2</sub>) is 2.0129936,
the sd for *l**o**g*(*β*<sub>1</sub> \* *β*<sub>2</sub>) is 0.0238808,
95% CI for *l**o**g*(*β*<sub>1</sub> \* *β*<sub>2</sub>) is \[1.9649542,
2.0580447\].

Show mean, 95% CI, and sd for *r*<sup>2</sup>

``` r
r_square_result_df = weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(.id, r.squared)
```

``` r
r_square_result_df %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    x = "r_squared",
    title = "Distribution of Estimates of r_squared")
```

<img src="p8105_hw6_yl4925_files/figure-gfm/unnamed-chunk-20-1.png" width="90%" />

Distribution is close to normal distribution.

``` r
r2_numerical_result = r_square_result_df %>% 
  summarize(
    lower_limit = quantile(r.squared, 0.025),
    upper_limit = quantile(r.squared, 0.975),
    r_square_mean = mean(r.squared),
    r_square_sd = sd(r.squared)) 
r2_numerical_result %>% 
  knitr::kable()
```

| lower\_limit | upper\_limit | r\_square\_mean | r\_square\_sd |
|-------------:|-------------:|----------------:|--------------:|
|    0.8940035 |    0.9269994 |       0.9115706 |     0.0085232 |

``` r
r2_mean = r2_numerical_result$r_square_mean
r2_sd = r2_numerical_result$r_square_sd
r2_lower = r2_numerical_result$lower_limit
r2_upper = r2_numerical_result$upper_limit
```

The mean for *r*<sup>2</sup> is 0.9115706, the sd for *r*<sup>2</sup> is
0.0085232, 95% CI for *r*<sup>2</sup> is \[0.8940035, 0.9269994\].
